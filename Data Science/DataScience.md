# Data Science 
*Date Last Locally Modified: January 17, 2023*
# [Learn Data Science Tutorial - Full Course for Beginners](https://www.youtube.com/watch?v=ua-CiDNNj30) by freeCodeCamp.org


*Date: Jan 16, 2023*
# Introduction to Data Science
**Tools:** coding, statistics and math
>**Goal of Data Science:** 
>Get insight from data. Everything signifies.


### Date Science
1. Coding, math and statistics in applied settings
2. The analysis of diverse data
3. In clusive analysis

>Uses ALL data to get the more insightful and compeling answer to your reserach questions.

#### It has rare qualities and high demands.
**rare qualities**

* DS takes unstructured data then finds order meaning and value

**high demand**
* provides insight and competitive advantage
* 140k-190k more deep analytical talent positions
* 1.5 million more data-savvy managers needed to take full advantage of big data in United States
* **people who speak data are in demand**
* Hottest job accoridng to LinkedIn: Stat analysis and data mininng
* Best job in America: Data Scientist
* **Data Science pays**

### **The Data Science Venn Diagram aka the Ingredients of Data Science**
 According to Drew Way, Data Science is teh intersection of three things
 * **Coding** - programming
 * **Stats** - quantitative ability
 * **Domain** - familiarity with field of practice: business educttion, etc
 
 <img src="Note%20Images/Data%20Science%20Venn%20Diagram%201.png" alt="drawing" style="height:300px;"/>


#### Coding
* gather and prepare data
* data comes from novel sources and unusual formats
* Stats: `R` & `Python` (Open source)
* Databas: `SQL`
* Command line: `Bash`
* Search: `Regex`

#### Stats or Maths
* probability, algebra, regression ets
* You can choose procedures and diagnose problems

#### Domain
* expertise in the fireld
* goals, methods, and constraints
* you need to implement it well

### **Other Intersections**
* Machine Learning
* Traditional Research
* Danger Zone

<img src="Note%20Images/Data%20Science%20Venn%20Diagram%202.png" alt="drawing" style="height:300px;"/>

#### Machine Learning
* Coding and math without domain
* A "Black box". You don't need to know what the meaning of it
* No applications in specific domain knowledge

#### Research
* Math and domain without coding
* data is structured
* Effort is in method and interpretation

#### Danger Zone
* Coding and domain without math
* unlikely to happen
* word counts and maps, can still be insightful
 
### Background where people come from
* Code - coders (most common)
* Stats - statisticians (less common)
* Domain - business people (least common)

### The Data Science Pathway
*One step at a time*

<img src="Note%20Images/Data%20Science%20Pathway%201.png" alt="drawing" style="height:300px;"/>


#### Planning
1. Define goals
2. Organize resources
3. Coordinate people
4. Schedule project

#### Data Prep
5. Get data
6. Clean data - large part of the process
7. Explore data
8. Refine data - choosing sections to include or exclude

#### Modeling
9. Create model - ex. regression analysis or neural network
10. Validate model - ex holdout validation or replication
11. Evaluate model - what does the it mean and how much does it tell you
12. Refine model - so it's easier to interpret and apply

#### Follow up
13. Present model - show in a way meaningful to people, ex client
14. Deploy model
15. Revisit model
16. Archive assets - document and make it possible for others to repeat it

In Summary
* Data Science is not just technical
* Contextual skills matter - how it is implemented and knowing how it works in particular field
* One step at a time

### Roles in data science
since it tends to be a collaborative thing

#### Engineer
* Focus on back end hardware, software, server
* Makes Data Science possible
* Developer, Data Base Administrators
* prvides foundation

#### Big Data Specialist
* Focuses on computer science and mathematics
* provide algorithm for machine learning to process very large amount of data
* create data products - is any tool or application that processes data and generates results

#### Researcher
* focus on domain specific research: physics, genetics
* strong statistics

#### Analyst
* day-to-day tasks of running a business
* web analytics, SQL
* good for business

#### Business people
* run the business
* frames business relevant questions
* manages projects
* must speak data

#### Entrepreneur
* needs data and business skills
needs to be creative 

#### Full-stack "unicorn"
* can do all things in expert level
* **unicorn** since they might not exist

> Data Science is diverse. People have different goals and skills and works in different context. But all of them are connected to Data Science


### Teams in Data Science
**Data Science has many tools and different people are gonna be experts on each one of them**

<img src="Note%20Images/Data%20Science%20Teams%201.png" alt="drawing" style="height:300px;"/>


The unicorn can do all of these. But again, they might not exist.


Team is  a way of gathering people with different abilities to put together their skilas to be unicorns. A unicorn by team!

> Take several people and make collective unicorn

*~Date: Jan 17, 2023~*
### Big data 
Similar but not the same

<img src="Note%20Images/Big%20Data%20Venn%20Diagram%201.png" alt="drawing" style="height:300px;"/>

Big data and Data Science combined is **Big Data Science**

<img src="Note%20Images/Big%20Data%20Science%201.png" alt="drawing" style="height:300px;"/>


#### Big Data without Data Science
- without all three V
- Machine Learning & word counts may not be Data Science
- Need atleast two skills: Coding and Quantitative skills

#### Data Science without Big Data
- Data with just 1 V
- Genetics Data
- streaming sensor data. NOt saving big data, just checking one section
- Facial recognition

#### Big Data Science
- situation with Volumne, velocity and & variety in data
- need the full skills set
- coding, stat and domain expertise

#### In summary:
- Big data != Data Science
- but they have some common griund
- Big data Science

### Coding
- machine talks
- task instrutions. like recipe
- user input then you get output

#### Coding & data
- ex. word counts. simple. domain expertise and math is not vital 
- buyt to make valid inferences and generalization, in face of variability and uncertainity in data, you need statistics and by extension Data Science

#### Tools
A. for coding

B. for Data Science

##### Tools for Coding

<img src="Note%20Images/Tools%20for%20Coding%201.png" alt="drawing" style="height:300px;"/>

##### Tools for Coding and Data Science

<img src="Note%20Images/Tools%20for%20Data%20Science%201.png" alt="drawing" style="height:300px;"/>

##### Tools for Data Science

<img src="Note%20Images/Tools%20for%20Data%20Science%201.png" alt="drawing" style="height:300px;"/>

#### In summary:
- Coding != Data Science
- Share tools and practices
- But statistics is critical


### Statistics
- Statistics is one part of Data Science
- share procedures with Data Science
- 

#### Where does Data Science and Statistics diverge?

<img src="Note%20Images/Data%20Science%20vs%20Statistics.png" alt="drawing" style="height:300px;"/>

- both analyze data
- but separate ecological niches

#### In summary:
- Data Science and Stats both use data
- Practicioners have different backgrounds
- ...and share different goals and contexts

### Business Intelligence
- Data in real life
- Purpose is to use data on internal operations, market, competitors etc 
- ...and make justifiable decisions 
based on data 

#### Data sicene?
- no coding in BI
- simple statistics
- BI focus is on domain expertise and utiliy

#### Data Dashboards
- collection of chats and tables that go together that gives you overview on what's going on in your buisiness
- user interaction and accessibility of information

#### Where does Data Science and Business Intelligence diverge?

<img src="Note%20Images/Data%20Science%20vs%20Business%20Intelligence.png" alt="drawing" style="height:300px;"/>


#### In summary:
- BI is very goal-oriented
- D&S prepares data and set up the form
- DS can learn from BI

## Ethical Issues
---
> Do no harm

1. Privacy
2. Anonymity

### Privacy
- confidentiality is important
- sources are not intended for sharing
- make sure that when you scrape data, you are allowed to do that


### Anonymity
- not hard to identify people in Data. ex gps data
- Health Insurance Portability and Accountability App - before this it's easy to identify people from medical record
- Propriety data may have identifiers. You amy know who the peopl are
- Even if you do know who they are, make sure to maintain privacy and confidentiality of the data
- make effort to make data anonymous

### Copyright
- people try to lockdown information
- scraping data is common and useful
- assumption that just becuause it's on the web, it's okay to use it is NOT true
- check copyright

### Data Security
- be concerned about hackers trying to come in and steal the data especially if it has identifying information
- ensure to the best of your ability that the data is safe and cannot be broken if it's stolen

### Other Ethical IssueS: Potential Bias and Overconfidence

<img src="Note%20Images/Potential%20Bias%20and%20Overconfidence.png" alt="drawing" style="height:300px;"/>

- DS has potential and risks
- Analyses can't be neutral
- Good judgement is vital

## Methods overview
---
Tech is the means in doing Data science. But getting **insight or the ability to find meaning out of the data is the goal**
1. **Sourcing** - how to get the data that goes into data science
2. **Coding** - computer programming to obtain, manipulate and analyze data
3. **Math** - math behind the DS methods
4. **Stats** - statistical methods to summarize and analyze data
5. **Machine Learning** - methods for finding clusters, predicting categories and scores

### Sourcing
- getting raw materials
- existing data, data APIs, scrape data or make data

#### existing data
- already in hand. in-house
open data. givernment or organization data open to public
- third paty data you can buy

#### data APIs
- Application Programming Interface - allows various application to communicate directly to each other.
- get web data
- direct import to whatever program you are using to analyze data

#### scrape data 
- for web data without APIs
- data in HTML, web tables,PDFs etc
- you can do it using apps and code

#### make data
- here, you can be specific and get exactly what you need
- interviews, surveys, experiments

#### GIGO
> GIGO- Garbage in, Garbage out
> - bad data in results to bad data out
##### Helpful tools:

<img src="Note%20Images/Ways%20to%20analyze%20data%20better%201.png" alt="drawing" style="height:300px;"/>

#### In summary
- data sourcing is important since you need to get raw materials
- many possible methods
- check quality of the data

### Coding
Any technology that lets you manipulate the data
1. **Apps** - specialize apps for working with data
2. **Data** - special formats for web data
3. **Code** - languages that give you full control

####  Apps
- spreadsheets like excell or google sheets
- Tableau
- SPSS
- JASP

#### Data
- HTML, XML, JSON, data encapsulated in the web

#### Code
- R, Python, SQL
- C, C++, & Java usually in backend
- Bash
- Regex

#### In sum
- use tools wisely
- a few tools is usually enough
- focus on your goal

### Math 
- forms the foundation
- how much math is enough. why do we need math if computer can do it?
1. Know which procedures to use and why
2. You need to do when things don;t work right. Understand what is it in the algorithm that doesn't work in the procedure
3. Some math is easier and quicker by hand than by computer

#### Analogy: Math:Data science
- Chemistry: Cooking, Kinesiology: Dancing, - Grammar: Writing
- You will do data science better if you have math skills

#### Algebra
- elementary algebra
- Linear (matrix) algerbra
- Systems of linear equations

#### More math
- Calculus
- Big O - how fast it workds
- Probability
- Baye's theorem

#### In sum
- math helps us make informed choirces
- find and fix problems
- can even do by hand to save time and effort

### Stats
**Attempts order in chaos**

#### Explore
- explore grraphics
- explore statistics
- descriptive statistics

#### Inference
- you can infer wind by looking at smoke. 
- From samples to populations. Get sample and infer about puopulation
- Hypothesis testing
- Estimation

#### Details
- feature selection
- problems taht can come up
- validation- see if data is accurate
- estimators
- fit - how well model fits data

#### Beware the trolls
- there's no one single way
- all models are wrong but **some are useful**

#### Wave your DIY falg
- You are doing something. Go do it!

#### In sum
- Explore, describe, and Infer
- Many choices available
- Remember: **Goal is useful insight**

### Machine Learning
- intersection of coding and stat

#### Goal: Data space
- reduce dimensionality. Find essential part of data
- clustering
- k-Means
- find anomalies

#### Categories
- Logistic regression
- kNN
- Naive Bayes
- Decision trees
- SVM
- Neural nets
- help fin patterns t get cohesion about these grouips

#### Predictions
- Linear regression
- Poisson regression
- Ensemble models- use differnet models and take prediction form eahc put together for more reliable predictions

#### In  sum
- use to categorize and predict
- many choices available
- Remember: **Goal is useful insight**

## Communicating
---
#### Interpretability
- lead people to a path on your data
- Tell **DAta-driven stories**
- solve for value.
- `Analysis != Value`
- `Analysis X Story == Value`
- Our goal is `Max(Value)`

#### Goals
- Analysis is goal-driven
- story should match goals
- answer questions clearly and unambigously

#### Client is not You
- egocentrism - you think othe rpeople understand what you know. Put it in terms of what client understand
- fals consensus - not everybody knows that
- anchoring - dont give false impression in the beginning
0- have clarity and explain yourslef in each step

#### Answers
- state the question
- give your answer
- qualify as needed
- go in order
- dicuss process sparingly. Explain technical details only when necessary

#### Analysis == Simplification
- Take overwhelmingness of data
- Everytings should be made as simple as possible, but not simpler.
- Less is more.
- Be minimally suffiecient
> Show just enough to answer the problem.

<img src="Note%20Images/Less%20is%20more%201.png" alt="drawing" style="height:300px;"/>


#### Example
Example:

<img src="Note%20Images/Simpsons%20Paradox%20Example%201.png" alt="drawing" style="height:300px;"/>
But they didn't check per department

<img src="Note%20Images/Simpsons%20Paradox%20Example%202.png" alt="drawing" style="height:300px;"/>


##### Simpson's Paradox
- Bias is neglible at department leveol
- possible bias in favor of women
- women applied to more selective program, with low acceptance rate

##### Questions you may ask
- Why do the program vary in class size
- acceptance rates vary
- admissions criteria
- promotional strategies
- prior education of applicants
- funding levels for each of programs

#### In sum
- stories give value
- address client;s goals
- Be minimally sifficien. Be concise and mek your message clear

## Actionable Insights
---
> **Data is for doing**
> *My thinking is first and last and always for the sake of my doing*

### Point the way
- when doing analysis, point the way
- why wa the project conducted
- goal is usally to direct action
- **analysis should guide actions**

### Next steps
- give next steps
- tell them what to do now
- justify with data
- be specific
- make sure it's doable by the client
- build on each step

### Corellation vs Causation
You data gives you correlation. But your client wants causation.
- How do you get from correlation to causation?
1. **Experimental studies** - randomized, controlled trials are simplest path to causaility
2. **Quasi-experiments** - methods that use non-rendomized data (usually obsetrvational data) for causal inference. 
3. **Theory and experience** - research based theory and domain-specific experience. Your client can you help you here especially when theyhave more domain experience tahn you do.

#### Social Factors
- some proposed to add **Social** in the Venn Diagram

<img src="Note%20Images/Data%20Science%20Venn%20Diagram%203.png" alt="drawing" style="height:300px;"/>

- Important to understand how things will play out

You need to be aware of the following:
- Client's mission
- Client's identity
- Business context
- Social context

Your recommendations will affect relationships

#### In Sum
- DS is goal focused
- Give specific next steps
be ware of social, economical,  political context

## Presentation Graphics
---
Paint a picture for the benefit of your client

### Goals of Graphics depends of what graphics you are using

#### Exploratory graphics
- **needs speed and responsiveness**
- quick and effective usually for client insihgt

<img src="Note%20Images/Exploratory%20Graphics%201.png" alt="drawing" style="width:500px;"/>  <img src="Note%20Images/Exploratory%20Graphics%202.png" alt="drawing" style="width:500px;"/> <img src="Note%20Images/Exploratory%20Graphics%203.png" alt="drawing" style="width:500px;"/> <img src="Note%20Images/Exploratory%20Graphics%204.png" alt="drawing" style="width:500px;"/> <img src="Note%20Images/Exploratory%20Graphics%205.png" alt="drawing" style="width:500px;"/>  <img src="Note%20Images/Exploratory%20Graphics%206.png" alt="drawing" style="width:500px;"/>


#### Presentation graphics
- **needs clarity and narrative flow**

##### Clarity vs Distraction
Things that can go wrong. These can be a distraction
- Colors
- 3D
- Interaction
- Animation

> *Make it clean as possibile. Communicate clearly.*

##### How *not* to do things:

#### Creating Narrative Flow
Example:

<img src="Note%20Images/Creating%20Narrative%20Flow%201.png" alt="drawing" style="width:300px;"/> 

Observe that even the charts have flow

<img src="Note%20Images/Creating%20Narrative%20Flow%202.png" alt="drawing" style="width:400px;"/> <img src="Note%20Images/Creating%20Narrative%20Flow%203.png" alt="drawing" style="width:400px;"/> <img src="Note%20Images/Creating%20Narrative%20Flow%204.png" alt="drawing" style="width:400px;"/> <img src="Note%20Images/Creating%20Narrative%20Flow%205.png" alt="drawing" style="width:400px;"/> <img src="Note%20Images/Creating%20Narrative%20Flow%206.png" alt="drawing" style="width:400px;"/> <img src="Note%20Images/Creating%20Narrative%20Flow%207.png" alt="drawing" style="width:400px;"/> <img src="Note%20Images/Creating%20Narrative%20Flow%208.png" alt="drawing" style="width:400px;"/> <img src="Note%20Images/Creating%20Narrative%20Flow%209.png" alt="drawing" style="width:400px;"/> <img src="Note%20Images/Creating%20Narrative%20Flow%2010.png" alt="drawing" style="width:400px;"/> 

#### In sum:
- Presenting is not exploring
- Be clear and be focused on what you are tellling
- Create a strong narrative that gives a different level of perspoective and answers question. More solid analysis

## Reproducable research
---
Play that song again
> Theyt are incremental, cumulative and adaptive.

### Show your work
1. Reviesing
2. Borrowing
3. Handing off
4. Accountability - show you did it in responsible way and conclusions are justified

#### Open data science Conference - [ODSC.com](ODSC.com)
-  Devoted to Open Data science to make method transparent around them

#### Open Science Framework - [OSF.io](OSF.io)
- way of sharing your data and method on how you got through the whole things
-makes research transparent

### Archives
- archive your data. make it available
- all data sets, both raw and processed
- all code to process and analyze data
- comment liberally and explain yourself

### Process
- explain why you did it the way you did it
- include choices, consequences, backtracking

### Future proofing
1. Data - store data in non-proprietary formats, like CSV
2. Storage - Place files in a secure, accessible location like GitHub
3. Code - Dependency management withpackrat for R or virtualenv for Python


>**Explain yourself**. A neat way to do taht is to put your narrative in a notebook ex. 

1. **[Jupyter](jupyter.org)** for Python

<img src="Note%20Images/Notebook%20Jupyter.png" alt="drawing" style="height:300px;"/>

2. **[R Markdown](rmarkdown.rstudio.com)** for R

<img src="Note%20Images/Notebook%20RMarkdown.png" alt="drawing" style="height:300px;"/>

### In sum:
- You should make your work and archive information in a way that **support cllaboration**
- Future-proof your work
- Share your narrative

## Next Steps - What to do after this Introductory Course?
---
1. R & Python - Do some coding
2. Data Visualization
3. Statistics and math - brush up
4. Machine Learning - learn in the practice of Data science
5. Sourcing out data - scraping

> Keep it in context.

DataKind.org
- harnessing the power of data science in the service of humanity

> Data science is democratic.


*Date: 1/18/2023*
# Data Sourcing
*with Barton Poulson*
> **Data Opus** 
> - Data Needed
> - No data. No Data Science

Methods for...
* measuring and evaluating data
* accessing existing data
* creating new custom data

## Metrics
> Know your target

**Goals**

* **Action** - Goal is to do something
* **Explicit** - Goals can guide effort
* **Client** - can help you prevent frustration. They know what you are working on
* **Analyst** - Goal exist for the benefit of analyst since they help you use your  time well

### Define sucess
- in your particular project or domain
- ex. Commerce, Education, GOvernment Research
- each domain has differents tandard of sucess

### Metrics
- Business metrics
- Key Performance Indicators (KPIs)
- SMART goals
- Multiple goals


#### Business metrics
Common ways of measuring sucess:
1. **Sales revenue** - are you making more money
2. **Leads generated** - new customers or potential customers since associated with future sales
3. **Customer value** - you may have small number of customers but they have a lot of revenue. Useful in predictg overall profitability
4. **Churn rate** - losing and gaining customers and having turnover

#### Key Performance Indicators (KPIs)
- **Non-Financial** - something that mearsures overall productivity
- **Timely** - weekly, daily, constantly gathered info
- **CEO focus** - senior management team affects how the organization act on the KPIs
- **Simple** - everyone can understand it
- **Team-based** - so they can take joint responsibility in meeting each KPIs
- **Significant impact** - should have more than one important outcome. A and B
- **Limited dark side** - fewer possibility in reinforcing wrong behavior and rewarding people in exploiting the system


#### SMART goals
- Specific 
- Measurable  
- Assignable - to a particular person 
- Realistic - you can actually do it with resources you have at hand
- Time-Bound - so you know when it can get done
> Assess goal on each of the criteria. Good way to check if the goal to be used as a metric of sucess of organization.
#### Multiple goals
Tricky since
* easy to focus on one.
* hard to focus on many
* goals may conflict
* hence we need to optimize

#### In sum:
- Metrics help awareness
- Many methods available for defining success and measuring progress
- Balance multiple goals

### Accuracy
Don't waste effort

> One way to do this in a very quantitative fashion is to **make classification table**

<img src="Note%20Images/Classification%20Table%201.png" alt="drawing" style="height:200px;"/>

Four kinds of quantifying accuracy using diffrent standards:
- Sensitivity
- Specificity
- Positive predictive value
- Negative predictive value

#### Sensitivity
$$\dfrac{True\ positives}{Total\ present}$$

*If there's a fire, does the alarm ring?* You want this to alway happen
$Test\ Positive$ - there's an alarm

$Event\ present$ - there's a fire

$$\dfrac{True\ positives}{Total\ number\ of\ alarms}$$

#### Specificity
$$\dfrac{True\ negatives}{Total\ absent}$$

*If there isn't a fire, does the alarm stay quiet?* 
$Test\ Positive$ - no alarm

$Event\ absent$ - no fire 

no fire and the alarm is not ringing is what you waant

#### Positive predictive value
$$\dfrac{True\ positives}{Total\ positives}$$

*If the alarm rings, was there a fire?* 
$True\ positives$ - there's a fire

$Total\ positives$ - any time the alarm rings


#### Negative predictive value
$$\dfrac{True\ negatives}{Total\ negatives}$$

*If the alarm doesn't ring, is there NO fire?*

$True\ positives$ - there's NO fire

$Total\ positives$ - any time the alarm doesn't ring

> Maximize each one as much as you can

#### In sum:
- Four kind of accuracy
- Different focus for each
- But the same overall goal: *identify* true positives and true negatives, and *avoid* false positives and false negatives

### Social context of measurement
*People are people*

>People can affect measurement

#### Business model
*An organization's business model is tied to its identity or reson to be.*

#### Restrictions
*Laws, policies, and common practices may limit the ways goals can be met.* You cannot do anything you want. You need to have constraints. Behave legally and ethically

#### Environemt
*Competition occurs both between organizations as well as within.* Office politics. Recommendations need to play well in the office in order for it to have maximum effectiveness.

#### Manipulation
*Any reward system will be exploited and people will game the system.* 

> Don't give up. Just be aware of these particular issues.

#### In sum
- Social factors affect goals.
- Limits and consequences
- Be sensitive with metrics and how people will adapt

## Existing Data
- easiest way to get data: in-house data, open data, & third-party data

1. Proprietary - in-house data
2. Public - open data
3. Purchased - third-party data

### In-house
- can be fast and easy - may already be in the organization
- format maybe appropriate for the software you are using
- documentation - maybe good
- quality control - you don;t know how opeople gathered it
- restrictions - you may not publish or you may not be allowed to use it

| Pros | Cons |
|-|-|
|Potentially quick, easy & free|May not exist|
|May be standardized|Documentation may be inadequate|
|Original team who gathered it may still be there|Quality may be unertain|
|May have identifiers in the data which can allow you to have individual level analysis||


### Open data
- Prepared data that's freely available
- Government data
- Corporate Data
- Scientific Data

#### Examples
* [US government open data](data.gov)
* [UNICEF](unicef.org/statistics)
* [World Health Organization](who.int/gho)
* [PewResearchCenter](pewinternet.org/datasets)
* [New York Times](developer.nytimes.com)
* [Google Public Data](google.com/publicdata)
* [Amazon AWS Public Data Stes](aws.amazon.com/datasets)

| Pros | Cons |
|-|-|
|Valuable Data Sets|Biased Samples|
|Range of topics, times, groups, etc| Meaning may not be clear|
|Well-formatted & well-documented|May need to share analyses|
||Issues with privacy and confidentiality. NO identifiers|
### Third-party data
- Data-as-aService (DaaS)
- Data brokers
- Can provide many topics
- May process data for you

#### Examples
* [Acxiom](acxiom.com)
* [nielsen](nielsen.com)
* [DATASIFT](datasift.com)

| Pros | Cons |
|-|-|
|Save time and effort|can be expensive|
|Individual level. Can provide identifiers|Still need to validate if it is what you want|
|Can get summaries and inferences|Distasteful to many people|

### In Sum
- Data science needs data
- 3 P's of data sources
- Pay attention to quality and usability of data
 to help you along in your projects

 ## APIs
 APIs have heard apps singing each to each

 ### API basics
 - Application Programming Interface
 - Allow programs to talk to each other
 - Get web data - API allows your program to directly get web on it's own grab the data and bring it back in

#### REST API
- most common API
- Representational State Transfer
- access data on web via HTTP
- Data in JSON format
- Send to other programs
- Lanugage agnostic - any programming langugae can send  and get data

### Kind of APIs
|Social APIs|Visual APIs|
|-|-|
|Facebook|Google Maps|
|Twitter|YouTube|
|Google Talk|AccuWeather|
|FourSquare|Pinterest|
|SoundCloud|Flickr|

> You can pull in data from any of these sites and integrate it to you own site or to you data analysis
### Programs that can be used
- R
- Python
- Bash
- Etc.

<img src="Note%20Images/Dataquest%20API.png" alt="drawing" style="height:200px;"/>

### In sum:
- APIs make web data easy
- Straight into programs
- Great for data science

## Scraping
Data hinding into open. Pull information from webpages

### Formats:
- HTML text
- HTML tables
- PDFs
- Media

> Pay attention to copyright & privacy. Make sure it's publicly available

### Formats
|Apps|Code|
|-|-|
|import.io|R|
|ScraperWiki|Python|
|Tabula|Bash|
|Google Sheets|Java|
|Excel|PHP|

> Look for information in the webpage

### HTML Text 
- Pull structured text from web pages
- use HTML tags
- \<body>,\<h1>,\<p>
### HTML Table
- HTML table tags
- \<table>,\<tr>,\<td>
- Need table  number which can be found by trial and Error

#### Example
* In a Wiki Page, you may find a table
<img src="Note%20Images/HTML%20Table%201.png" alt="drawing" style="height:400px;"/>
* To pull it you may use Google sheet. *Poke around to get the number of table*
<img src="Note%20Images/HTML%20Table%202.png" alt="drawing" style="height:400px;"/>
```
=IMPORTHTML("https://en.wikipedia.org/wiki/Iron_Chef_America","table",2)
```

#### You may also scrape from PDFs
- Be aware if its Native (text) or scanned
- Text elements
-Raster/ vectore images
-Tabualr data - but you may have to use speciallized program like Scraperwiki to get taht

### Media
- Images, video, audio
- Gettimg images easy
- Reas data by looping pixel by pixel

### In sum:
- If no APIs, try scraping
- USe apps or code
- Be sensitive Copyright and privacy
 ## Creating New Data
(Data ne novo* - new data

### Strategies
|Role?|Q/Q?|How?|
|-|-|-|
|Passive|Quantitative|Online|
|Active|Qualitative|In person|

### Options
* Interterview
* Surveys
* Card sorting
* Experiments

### Experiments
Laboratory
- In-person projects where you shape information or an experience

A/B Testing
- Automated, online testing of two or more variations on a webpage.

#### In sum
- When you create data, you get exactly what you need
- If you can't find it, make it.
- Many possible methods.

### Interviews
a conversation with another person or group 

#### Why do interview?
1. You are working with a new topic
2. You are working with a new audience
3. You need to find ways to improve

> You don't want to constrain responses.

#### Types
|Structured|Unstructured|
|-|-|
|You have **predetermined** set of questions; everyone gets the same questions in the same order|Much more like a conversation where questions arise in response to answers; different for each person|

> Can be done in person, phone, or online

*Date: 01/19/2023*
#### Keep in mind 2:17:20
- Time - can range from minutes to hour per person
- Training - special skill that requires specific training
- Analysis - Hardest part is analyzing answers for themes

> Yuu can learn thing you never expected.

#### In sum:
- Interviews are best for new situations
- It can be time-consuming
- May need special training for conducting and analyzing data

### Card sorting
YOu are trying to build **mental model**, model of people's meantal structures.

####  Basic Procesure
* Write topics on cards
* Physical or digital
* People sort cards
* Dissimilarity data -Take that information and get this

#### Kind of card sorting task
|Generative |Evaluative|
|-|-|
|Respondents create own sets using any number of groupings;used to design websites|Fixed number or names of categoriesl see uf navigation make sense to people.|

#### Dendogram
You'll end up with this visualization of the pieces of information
<img src="Note%20Images/Dendogram%201.png" alt="drawing" style="height:200px;"/>

#### Tools
* Optimal Workshop
* UserZoom
* UX Suite

#### In Sum:
- Card sorting allows us to see intuitive organization in heirarchal format
- We can do it with Physical and digital tools/choices
- In the end, you'll end up with a Hierarchical visualization. How information are structured and related to each other.

### Laboratory experiments
Goal is to know cause and effect.

> Researchers play active roles in experiments with **manipulations**.

#### Experiments
- Focused research
- Hypothesis driven
- Random assignment
- Confounds & artifacts - minimized by randomization

ex.
Eyetracking in web design, research in medicine, education and physchology.

> Experimental research is the goald standard for reliable valid information for cause and effects

#### However it comes at a cost
1. Requires extensive specialized training
2. Often time-consuming and labor intensive
3. Can be very expensive

#### In sum
- Laboratory experiment is the best method for causality
- controls for confounds
- can be difficult to do

### A/B testing
extremely common in the web world

#### Here's how it work
1. Create multiple versions - usually A and B or more
2. Randomly assign it to visitors
3. Compare response rates
4. Implement best variation

#### Response rates
You may look into 
- time on page
- mouse tracking 
- click-throughs
- shopping cart value
- abandonment

> contributes to Website optimization. To make it as effective as it can be

> It is performed continually.

> A/B Testing = Always be testing

#### Tools
* Optimizely
* VWO - Visual Web Optimizer

#### When you get the data...
You can use statistical hypothesis testing, and may want to adjust parameters.

#### In sum
- website experimentation
- Optimize design
- continual Assessment

### Survey
Just ask

> Do you know your topic and audience well enough to anticipate answers? YEs? Use survey

#### Types
- Closed ended
- Open eneded
- In perosn
- Online

#### Tools
- SurveyMonkey
- Qualtrics
- Google Forms
- Typeform

#### Pros and cons
|Easy to do| And do badly|
|-|-|
|Very easy to set up survey and send out to large groups of people|Questions can be ambiguous and response scales confusing|

> Meaning should be clear and unambiguoi=us

#### Beware the pushpoll
a biased attempt. Pushes on one answer

> Watch out for bias, in question wording, response options, and sample selection.

#### In sum
- Get lots of data quickly
- requires familiarity with possible answer of audience. 
- watch for bias

# Next Steps
Don't just sit there!

* **See what you already have**
* **Explore some open data sources**
* **If it helps, check a few data vendors**
* **Consider making data**

> Get what you need and get going!

01/20/2023
# Coding in Data science
with Barton Poulson

> Know your tools and know their proper place.

## Data Tools
Data tools is a subset of Data science

- Spreadsheets
- Tableau - data visualization program
- Web data - format used 

### Essentials
- R
- Python
- SQL

### ...and others
- C, C++, Java
- Bash
- Regex

> Don't forget the 80/20 rule or Pareto Principle
> Acomplishment of cumulative effectiveness. Only get the nth tools that is 20% of your the put

> You don't nexessarily need to learn everything. **Focus on the tools that will be the most productive for you**.

### In sum
- Coding is important
- Data science is greater than the collection of tools used in it
- Remember 80/20 rule when deciding what tools to use. You'll get a lot of bang in small set of tools.

## Applications
### Spreadsheets
It can be the right tool for Data science in a lot of circumstances
- They're everywhere
- Client's format
- Data tramsfer - csv is the universal format
- Easy to use

<img src="Note%20Images/Tools%20Ranking%201.png" alt="drawing" style="height:200px;"/>

#### Uses
- Good for data browsing
- sorting
- rearranging
-finding and replacing
- formatting
- transposing data
- tracking changes
- making pivot tables - explore data
- arranging output for consumption

#### Be concerened with Tidy data
- **Tidy data** for transferring data. Tidy it into format that really easy to import from one program to another
- `Column` == `variable`
- `Row` == `case`
- One sheet per file
- One level per file


#### In sum
- You need spreadsheets
- The right tool for DS
- Tidy Data for exporting

### Tableau Public
visualization program

> First look. see what you have

Go to [tableau.com](tableau.com) and go to Tableau Public, free version. File is saved in the web in public form.

This can be used to create graphics out of data (usually a tidy data in Excel/Spreadsheets)

<img src="Note%20Images/Tableau%201.png" alt="drawing" style="height:200px;"/>
- can do average, forecast, etc.


### SPSS - Statistical Package for the Social Sciences
[ibm.com/spss](ibm.com/spss)
A desktop program used in academics, medical and business research. Like a spreadsheet but has dropdown menu.

- has lot of hidden datasets
- `.sav` dataset files
- Can do Point-and-Click analysis

### JASP - Just Another Statistics Program
Free version of SPSS. Open Source.

[jasp-stats.org](jasp-stats.org) - Note: still Beta

Also, we can share it to [Open Science Framework](osf.io)

### Other software
There are so many choices

- SAS - expensive
- SAS University Edition - free
- JMP - visualization software
- STATA
- Minitab
- MATLAB
- Mathematica
- WolframAlpha
- RapidMiner
- KNIME
- Orange
- BigML
- SOFA Statistics - Statistics Open For All
- Past 3
- StatCrunch
- XLSTAT - within excel environment it self

> Use what best works for you

### What to consider in choosing tools
- Functionality
- Ease of use
- existence of a Community
- Cost

> Don't forget the 80/20 rule. You can do a lot with few tools
### In sum:
- Applications are tools
- Goals drive choice
- What works for *you*?

## Web data
### HTML - Hyper Text Markup Language 
- Make the World wide web go round.
- A text document that uses tags to define structure of document 
- Cascading Style Sheet (CSS) gives appearance of a web page
> If you want to extract information from the web, you need to understand how the web is structured.
#### In sum:
- The web runs on HTML
- HYML defines page structure
- Navigate to get data

### XML - eXtensible Markup Language
- Data, defined thyself
- XML is semi-structured data: 
- Tags define data, but tags are free. You can define it anywhere you want. ex. `<genre><\genre>`,`<circuit><\circuit>`
- Tags use opening anc closing angle brackets like HTML 
**Uses**
- Web data
- Microsoft Office
- iTunes library
- Data files

#### Easy Convert between formats
1. XML to CSV
2. HTML to XML
3. CSV to XML

#### In sum:
- XML is semi-structured data: 
- common for web data
- easy to translate fromat back in forth

### JSON - Java Script Object Notation
- smaller, better
- semi-structured data like XML
- gradually taking XML's place
- easy to convert

|XML|JSON|
|-|-|
|Markup Language that gives meaning to text|Designed for data interchange|
|Allows comments and metadata in tags|Corresponds with data structures|
||Typically shorter thatn XML|


[JSON helpful tool to structure unorganize data](jsonprettyprint.com)

#### In sum:
- JSON is semi-structured
- designed for data interchange
- replacing XML on web as container for data in web pages

## Languages
### R
- Free and open source
- Specially developed for vector operations
- has great community
- 7000+ packages, can do anything
- ... hence its popularity

<img src="Note%20Images/Tools%20Ranking%202.png" alt="drawing" style="height:200px;"/>

#### Interfaces
- R comes with its own IDE
- TErminal can also be used
-[RStudio.com](RStudio.com)
- Jupyter
- R is all command line

#### Comamnds
- can enter in console
- save scropts and run selectively
- Idiosyncratic model - R is a little weird. It has slightly different format than the other programming languages

#### Details
- Graphs in separate window
- Text and numbers in console
- Can save output to files. POrtable

#### Packages
R has packages to expand its capabilities
- There are two sources

|CRAN|Crantastic!|
|-|-|
|Comprehensive R Archive Network||
|[cran.rstudio.com](cran.rstudio.com)|[crantastic.org](crantastic.org)|
|Task views|Shows popularity and updates|
|Datsets, manual and vignettes||

#### In sum:
- R is the language of Data science
- command line interface
- thousands of packages are available

### Python
A language that can do it all
- General purpose. Easy to use
- Built-in on Mac/Linux
- Great community
- Thousand of packages 

<img src="Note%20Images/Tools%20Ranking%203.png" alt="drawing" style="height:200px;"/>

#### Details
|||
|-|-|
|Version:| Both 2.x & 3.x|
|Problem:|Compatibility|
|And so:|Many use 2.x since most Data science packages use 2.x|

#### Interface
- Python's IDLE
- Terminal/IDE
- Jupyter/IPython
- Two companies that made special distributions of Python to make it easy to use with data: **Continuum Anaconda** & Enthough Canopy
- All command line. Lines of code

#### Commands
- text interface
- Python is familiar to millions of coders
- Simple adaptations for data

> Data science loves Jupyter
- Text output and markdown
- Inline graphics
- Easy to organize and present

#### Packages: 
- PyPi
- NumPy and SciPy
- Matplotlib & Seaborn
- Pandas
- scikit-learn

#### In sum
- Python is popular and familiar
- general purpose
- thousands of packages

### SQL - Structured Query Language
- Language of databases. That's where the data is
- SQL is a language
- For relational databases
- Structured data
- then export data


<img src="Note%20Images/Tools%20Ranking%204.png" alt="drawing" style="height:200px;"/>

#### RDBMS - Relational Database Management System
- Orcale Database
- Microsoft SQL Server
- MySQL - open source and free
- PostgreSQL - open source and free

> SQL helps minimize data redundancy by using connected tables.

|Graphical User Interface GUI|Text|
|-|-|
|SQL Developer|Any command line interface|
|SQL Server|Any IDE|
|Management Studio||
|Toad, etc||

#### Basic Command
* `SELECT` - choose cases
* `FROM` - which table from
* `WHERE` - conditions
* `ORDER BY` - way of putting it tobgether

pull out information and send the data to you program of choice (ex. R or Python)

#### In sum
- For relational databases
- Basic commands are useful
- Data typically exported to other propgram for analysis

### C, C++ & Java
-You can find these languages in the bedrock: the absolute fundamental layer that makes Data science possible
- use this if time is of the essence
#### C/C++
- C is from 1960s
- C++ is from 1980s
- very wide usage
- fast and stable - used as benchmark how fast is a language. server used
- can be used in R

#### Java
- based on C/C++
- WORA: Write Once, Run Anywhere
- MOst popular language overall against all tech situations

#### Who uses it?
|Engineers|Analyst|
|-|-|
|Engineeres and developers deal with the inner workings or back end of data science|Typically don't do hands-on work with foundation; more work on the front end|

#### In sum
- C, C++ and Java for foundation back end. Data's back end
- Fast and reliable
- Typically for engineers

###  Bash
- Old tools and still uised productively with new data

#### Command line
- CLI - Comman Line Interface
- predates monitors
- method of interacting, not a language

#### Shells
- shell = language
- Macs and Linux - Bash:  Bourne Again Shell
- Windows: PowerShell
- Boune shell, C shell, Z shell, fish, etc.

#### Things to know
1. Prompt - indicates that you should type your command here. In bash it is  `$`
2. One line at a time
3. You can run a script wihich is a text document

#### Utilities
- specific programs that accomplish specific tools

Built-ins
- installed
- examples of utilities:
1. cat
2. awk
3. grep
4. sed
5. head and tail
5. sort and uniq
6. wc
7. printf

Installables
- other commandline utilities you can add
1. jq
2. json2csv
3. Rio
4. BigMLer

#### In sum:
- command line survives because it is extremely effective with data
0 utilities are fast and easy
0 active development of utilities

### Regex
- needles in haystack
- cryptic
- ex. finding out if its a valid email address
```
^[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}$
```
- way of **pattern matching** 
- specific or general pattern
- you can export them to another program for analysis

<img src="Note%20Images/Regex%201.png" alt="drawing" style="height:200px;"/>

#### Elements
- Literals
- Metacharacters - code that gives representation
- escape sequences
- search expression
- target string

<img src="Note%20Images/Regex%202.png" alt="drawing" style="height:200px;"/>

> Power come when you combine these
#### [Regex golf](regex.alf.nu) 
- exercise/ practice
- match all words on the left

#### In sum:
- Find thre right data
- Powerful and flexible
- Cryptic but can be fun

## Conclusion - Next steps
- Get some tools
- Data Tools != Data Science. It is part od Data Science
- **Apps** - Excel and Tableu
- **Code** - R and Python
- **Utilities** - Bash and regex
- **Domain** - Field experience, intimate understanding of particular domain

> Get what's best for *your* needs and *your* style. Tools are means to an end. Focus on the goa

> Goal is always the meaning.

# Mathematics in Data Science